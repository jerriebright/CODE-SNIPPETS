{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "cassava_disease.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "xqJ2ItocwagR"
      },
      "source": [
        "!pip install pydot\n",
        "!pip install pydotplus\n",
        "!pip install graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hlQ-nDaMwagX"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import warnings\n",
        "import json\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "work_dir = '../input/cassava-leaf-disease-classification/'\n",
        "os.listdir(work_dir) \n",
        "train_path = '/kaggle/input/cassava-leaf-disease-classification/train_images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LlZXP5Bfwagb"
      },
      "source": [
        "data = pd.read_csv(work_dir + 'train.csv')\n",
        "print(data['label'].value_counts()) # Checking the frequencies of the labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Swd27XMawagb"
      },
      "source": [
        "# Importing the json file with labels\n",
        "with open(work_dir + 'label_num_to_disease_map.json') as f:\n",
        "    real_labels = json.load(f)\n",
        "    real_labels = {int(k):v for k,v in real_labels.items()}\n",
        "    \n",
        "# Defining the working dataset\n",
        "data['class_name'] = data['label'].map(real_labels)\n",
        "\n",
        "real_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "olZAQckewagc"
      },
      "source": [
        "# generate train and test sets\n",
        "train, test = train_test_split(data, test_size = 0.05, random_state = 42, stratify = data['class_name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kgD4W7-8wagd"
      },
      "source": [
        "IMG_SIZE = 456\n",
        "size = (IMG_SIZE,IMG_SIZE)\n",
        "n_CLASS = 5\n",
        "BATCH_SIZE = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ej1zkTr_wage"
      },
      "source": [
        "datagen_train = ImageDataGenerator(\n",
        "    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    fill_mode = 'nearest',\n",
        ")\n",
        "\n",
        "datagen_val = ImageDataGenerator(\n",
        "    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Rr5WDg-swagf"
      },
      "source": [
        "train_set = datagen_train.flow_from_dataframe(\n",
        "    train,\n",
        "    directory=train_path,\n",
        "    seed=42,\n",
        "    x_col='image_id',\n",
        "    y_col='class_name',\n",
        "    target_size = size,\n",
        "    class_mode='categorical',\n",
        "    interpolation='nearest',\n",
        "    shuffle = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        ")\n",
        "\n",
        "test_set = datagen_val.flow_from_dataframe(\n",
        "    test,\n",
        "    directory=train_path,\n",
        "    seed=42,\n",
        "    x_col='image_id',\n",
        "    y_col='class_name',\n",
        "    target_size = size,\n",
        "    class_mode='categorical',\n",
        "    interpolation='nearest',\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE,    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_KarHfMzwagh"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import EfficientNetB3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B_Z9aAScwagi"
      },
      "source": [
        "def create_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "    # initialize the model with input shape\n",
        "    model.add(\n",
        "        EfficientNetB3(\n",
        "            input_shape = (IMG_SIZE, IMG_SIZE, 3), \n",
        "            include_top = False,\n",
        "            weights='imagenet',\n",
        "            drop_connect_rate=0.6,\n",
        "        )\n",
        "    )\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(\n",
        "        256, \n",
        "        activation='relu', \n",
        "        bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)\n",
        "    ))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(n_CLASS, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "leaf_model = create_model()\n",
        "leaf_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "09Yn7hvnwagi"
      },
      "source": [
        "keras.utils.plot_model(leaf_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "G3e2g_yWwagj"
      },
      "source": [
        "EPOCHS = 15\n",
        "STEP_SIZE_TRAIN = train_set.n // train_set.batch_size\n",
        "STEP_SIZE_TEST = test_set.n // test_set.batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vg1dDe3Twagk"
      },
      "source": [
        "def model_fit():\n",
        "    leaf_model = create_model()\n",
        "    \n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(\n",
        "        from_logits = False,\n",
        "        label_smoothing=0.0001,\n",
        "        name='categorical_crossentropy'\n",
        "    )\n",
        "    \n",
        "    leaf_model.compile(\n",
        "        optimizer = Adam(learning_rate = 1e-3),\n",
        "        loss = loss, #'categorical_crossentropy'\n",
        "        metrics = ['categorical_accuracy']\n",
        "    )\n",
        "    \n",
        "    es = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        mode='min', \n",
        "        patience=3,\n",
        "        restore_best_weights=True, \n",
        "        verbose=1,\n",
        "    )\n",
        "    \n",
        "    checkpoint_cb = ModelCheckpoint(\n",
        "        \"Cassava_best_model.h5\",\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "    )\n",
        "    \n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=2,\n",
        "        min_lr=1e-6,\n",
        "        mode='min',\n",
        "        verbose=1,\n",
        "    )\n",
        "    \n",
        "    history = leaf_model.fit(\n",
        "        train_set,\n",
        "        validation_data=test_set,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "        validation_steps=STEP_SIZE_TEST,\n",
        "        callbacks=[es, checkpoint_cb, reduce_lr],\n",
        "    )\n",
        "    \n",
        "    leaf_model.save('Cassava_model'+'.h5')  \n",
        "    \n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nrzqsrtswagl"
      },
      "source": [
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
        "\n",
        "from tensorflow.compat.v1.keras import backend as K\n",
        "K.set_session(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-_RdDAqmwagm"
      },
      "source": [
        "try:\n",
        "    final_model = keras.models.load_model('Cassava_model.h5')\n",
        "except Exception as e:\n",
        "    with tf.device('/GPU:0'):\n",
        "        results = model_fit()\n",
        "    print('Train Categorical Accuracy: ', max(results.history['categorical_accuracy']))\n",
        "    print('Test Categorical Accuracy: ', max(results.history['val_categorical_accuracy']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KKI-kTZ2wagn"
      },
      "source": [
        "def trai_test_plot(acc, test_acc, loss, test_loss):\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,10))\n",
        "    fig.suptitle(\"Model's metrics comparisson\", fontsize=20)\n",
        "\n",
        "    ax1.plot(range(1, len(acc) + 1), acc)\n",
        "    ax1.plot(range(1, len(test_acc) + 1), test_acc)\n",
        "    ax1.set_title('History of Accuracy', fontsize=15)\n",
        "    ax1.set_xlabel('Epochs', fontsize=15)\n",
        "    ax1.set_ylabel('Accuracy', fontsize=15)\n",
        "    ax1.legend(['training', 'validation'])\n",
        "\n",
        "\n",
        "    ax2.plot(range(1, len(loss) + 1), loss)\n",
        "    ax2.plot(range(1, len(test_loss) + 1), test_loss)\n",
        "    ax2.set_title('History of Loss', fontsize=15)\n",
        "    ax2.set_xlabel('Epochs', fontsize=15)\n",
        "    ax2.set_ylabel('Loss', fontsize=15)\n",
        "    ax2.legend(['training', 'validation'])\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "trai_test_plot(\n",
        "    results.history['categorical_accuracy'],\n",
        "    results.history['val_categorical_accuracy'],\n",
        "    results.history['loss'],\n",
        "    results.history['val_loss']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}